# ğŸ§  ReducciÃ³n de Dimensionalidad con Python y Scikit-learn

Este proyecto explora diferentes tÃ©cnicas de reducciÃ³n de dimensionalidad utilizando `NumPy`, `Matplotlib` y `Scikit-learn`. Se aplican conceptos de anÃ¡lisis de componentes principales (PCA) y otros mÃ©todos como `LLE`, `Isomap`, `MDS` y `t-SNE`, sobre datos sintÃ©ticos y el dataset MNIST.

---

## ğŸ“š Contenido

### 1. **VisualizaciÃ³n y PCA desde cero**
- Se generan datos 3D simulando una curva con ruido.
- Se visualizan en 3D y luego se reduce a 2D mediante PCA hecho "a mano" con `SVD` de `numpy`.
- Se reconstruyen los datos y se analiza la pÃ©rdida de informaciÃ³n.

### 2. **PCA con `scikit-learn`**
- Se utiliza `PCA` de `sklearn` para realizar la reducciÃ³n de dimensionalidad.
- Se demuestra cÃ³mo estimar el nÃºmero mÃ­nimo de dimensiones necesarias para conservar un 95% de la varianza.

### 3. **Dataset MNIST**
- Se descarga el dataset de dÃ­gitos escritos a mano (784 dimensiones).
- Se aplica `PCA` para reducir las dimensiones mientras se conserva el 95% de la varianza.
- Se visualiza la comparaciÃ³n entre imÃ¡genes originales y comprimidas.

### 4. **TÃ©cnicas avanzadas de reducciÃ³n no lineal**
- `LLE (Locally Linear Embedding)`
- `MDS (Multidimensional Scaling)`
- `Isomap`
- `t-SNE`

Se aplican al conjunto de datos suizo (`Swiss Roll`) generado con `make_swiss_roll`, demostrando cÃ³mo se "desenrolla" un dataset no lineal.

---

## ğŸ§ª Requisitos

Instala las dependencias con:

```bash
pip install -r requirements.txt

ğŸ§‘â€ğŸ’» Autor

Desarrollado por Gus como parte de su aprendizaje en Python e IA.
